# System
sys:
  info_level: 3 # 0: no info, 1: INFO tags, 2: DEBUG tags, 3: INFO+DEBUG tags
  embedding_model: "all-roberta-large-v1" # all-MiniLM-L6-v2 (6-layer, 384-dim), all-MiniLM-L12-v2 (12-layer, 768-dim), all-mpnet-base-v2 (12-layer, 768-dim), all-roberta-large-v1 (24-layer, 1024-dim)
  hpc: false

# Logging
logging:
  level: DEBUG
  format: "[%(asctime)s] - %(name)s -%(levelname)s: %(message)s"

# Vector Store
vector_store:
  dimension: 1024 # 384, 768, 1024 depending on embedding model
  index_type: "IDMap,Flat"
  metric_type: 1 # faiss.METRIC_L2

# Cache
cache:
  CACHE_DIR: "./persistent_cache"

# Experiment
experiment:
  name: "Experiment 1"

  # Logging
  run_id: '006'
  # Dataset configuration
  dataset_name: "quora"
  load_from_file: false
  sample_size: 1000 # when using quora, sample_size is doubled due to question pairs
  partial_questions: true
  range_min: 0
  range_max: 12

  # Cache configuration
  use_cache: true # This does not do anything currently
  use_temperature: true
  max_cache_size: 2
  cache_strategy: "memory" # "memory" or "dynamic_eviction"
  eviction_policy: "AP"

  # LSH configuration
  use_LSH: true
  bucket_density_factor: 0.7
  num_hyperplanes: 8 # this defines the bucket size
  window_size: 1000
  sensitivity: 2.0
  decay_rate: 5.0
